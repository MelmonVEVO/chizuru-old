@online{deepmgo,
	title="AlphaGo",
	author="DeepMind",
	url="https://www.deepmind.com/research/highlighted-research/alphago",
	urldate="2022-11-04"
}

@article{mauldin83,
	title="{ROG-O-MATIC}: A Belligerent Expert System",
	author="Mauldin, M. and Jacobson, G. and Appel, A. and Hamey, L.",
	year="1983",
	publisher="Carnegie Mellon University"
}

@article{hessel17,
	title={Rainbow: Combining Improvements in Deep Reinforcement Learning},
    author={Matteo Hessel and Joseph Modayil and Hado van Hasselt and Tom Schaul and Georg Ostrovski and Will Dabney and Dan Horgan and Bilal Piot and Mohammad Azar and David Silver},
    year={2017}
}

@article{asperti17,
	title="Rogueinabox: An Environment for Roguelike Learning",
	author="Asperti, A. and De Pieri, C. and Pedrini, G.",
	year="2017",
	journal="International Journal of Computers",
	pages="146--154",
	volume="2"
}

@article{hochreiter97,
	title={Long short-term memory},
	author={Hochreiter, Sepp and Schmidhuber, J{\"u}rgen},
	journal={Neural computation},
	volume={9},
	number={8},
	pages={1735--1780},
	year={1997},
	publisher={MIT Press}
}

@article{vinyals19,
	title="Grandmaster level in StarCraft II using multi-agent reinforcement learning",
	author="Vinyals, O. and Babuschkin, I. and Czarnecki, W. M. and others",
	year="2019",
	journal="Nature",
	volume="575",
	pages="350--354"
}

@article{berner19,
	title={Dota 2 with large scale deep reinforcement learning},
	author={Berner, Christopher and Brockman, Greg and Chan, Brooke and Cheung, Vicki and others},
	year={2019}
}

@article{mnih15,
	title="Human-level control through deep reinforcement learning",
	author="Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Rusu, Andrei A and others",
	year="2015",
	journal="Nature",
	volume="518",
	pages="529--533"
}

@book{sutton18,
	title="Reinforcement learning: an introduction",
	author="Sutton, Richard S and Barto, Andrew G",
	year="2018",
	publisher="MIT Press"
}

@article{silver16,
	title="Mastering the game of Go with deep neural networks and tree search",
	author="Silver, D. and Huang, A. and Maddison, C. and others",
	year="2016",
	journal="Nature",
	volume="529",
	pages="484--489"
}

@book{jackson86,
	title={Introduction to expert systems},
	author={Jackson, Peter},
	year={1986},
	publisher={Addison-Wesley Pub. Co., Reading, MA}
}

@misc{gamasutra16,
	author       = {Gamasutra},
	howpublished = {https://www.gamedeveloper.com/design/-i-rogue-i-co-creator-permadeath-was-never-supposed-to-be-about-pain-},
	title        = {Rogue co-creator: permadeath was never supposed to be 'about pain'},
	year         = {2016},
	note = {[Online, Accessed 2023-04-24]},
}

@article{asperti18,
	author="Asperti, Andrea and Cortesi, Daniele and Sovrano, Francesco",
	title="Crawling in Rogue's dungeons with (partitioned) {A3C}",
	year="2018",
}

@article{matthews22,
	author="Matthews, M. and Samvelyan, M. and Parker-Holder, J. and Grefenstette, E. and Rockt{\"a}schel",
	title="Hierarchical Kickstarting for Skill Transfer in Reinforcement Learning",
	year="2022"
}

@article{jaderberg16,
  title={Reinforcement learning with unsupervised auxiliary tasks},
  author={Jaderberg, Max and Mnih, Volodymyr and Czarnecki, Wojciech Marian and Schaul, Tom and Leibo, Joel Z and Silver, David and Kavukcuoglu, Koray},
  journal={arXiv preprint arXiv:1611.05397},
  year={2016}
}
@inproceedings{izumiya21,
  title={Inventory Management with Attention-Based Meta Actions},
  author={Izumiya, Keisuke and Simo-Serra, Edgar},
  booktitle={2021 IEEE Conference on Games (CoG)},
  pages={1--8},
  year={2021},
  organization={IEEE}
}

@article{kuttler20,
  title={The nethack learning environment},
  author={K{\"u}ttler, Heinrich and Nardelli, Nantas and Miller, Alexander and Raileanu, Roberta and Selvatici, Marco and Grefenstette, Edward and Rockt{\"a}schel, Tim},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={7671--7684},
  year={2020}
}

@inproceedings{campbell17,
  title={Learning combat in {NetHack}},
  author={Campbell, Jonathan and Verbrugge, Clark},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence and Interactive Digital Entertainment},
  volume={13},
  number={1},
  pages={16--22},
  year={2017}
}

@article{hasselt15,
	title={Deep Reinforcement Learning with Double Q-learning},
	author={Hado van Hasselt and Arthur Guez and David Silver},
	year={2015},
}

@article{wang16,
	title={Dueling Network Architectures for Deep Reinforcement Learning},
    author={Ziyu Wang and Tom Schaul and Matteo Hessel and Hado van Hasselt and Marc Lanctot and Nando de Freitas},
    year={2016}
}

@article{kanagawa19,
      title={Rogue-Gym: A New Challenge for Generalization in Reinforcement Learning},
      author={Yuji Kanagawa and Tomoyuki Kaneko},
      year={2019}
}

@article{schaul16,
      title={Prioritized Experience Replay},
      author={Tom Schaul and John Quan and Ioannis Antonoglou and David Silver},
      year={2016}
}

@article{bellemare17,
      title={A Distributional Perspective on Reinforcement Learning},
      author={Marc G. Bellemare and Will Dabney and RÃ©mi Munos},
      year={2017}
}

@article{fortunato19,
      title={Noisy Networks for Exploration},
      author={Meire Fortunato and Mohammad Gheshlaghi Azar and Bilal Piot and Jacob Menick and Ian Osband and Alex Graves and Vlad Mnih and Remi Munos and Demis Hassabis and Olivier Pietquin and Charles Blundell and Shane Legg},
      year={2019}
}

@misc{bhattrl,
	author = {Shweta Bhatt},
	title = {Reinforcement learning 101},
	note = {[Online, Accessed: 2023-04-24]},
	howpublished = {https://towardsdatascience.com/reinforcement-learning-101-e24b50e1d292},
	year = {2018},
}

@misc{sebtheiler,
	author = {Sebastian Theiler},
	howpublished = "https://github.com/sebtheiler/tutorials/blob/main/dqn/train_dqn.py",
	title = "train_dqn.py",
	year = {2020},
}